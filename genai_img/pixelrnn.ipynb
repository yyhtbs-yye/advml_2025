{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "# Import einops if not already imported\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PixelRNN model using standard LSTM cells for classification\n",
    "class PixelRNN(nn.Module):\n",
    "    def __init__(self, input_channels=3, hidden_size=128, num_layers=2, num_classes=256):\n",
    "        super(PixelRNN, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Use standard PyTorch LSTMCell\n",
    "        self.cells = nn.ModuleList([\n",
    "            nn.LSTMCell(input_channels if i == 0 else hidden_size, hidden_size)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # output layer: output num_classes for classification\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        batch_size, nc, height, width = x.size()\n",
    "        \n",
    "        # Flatten image to 1D sequence\n",
    "        x_flat = x.view(batch_size, 1, height * width)\n",
    "        \n",
    "        # Initialize hidden and cell states for each layer\n",
    "        hidden_states = []\n",
    "        cell_states = []\n",
    "        for _ in range(self.num_layers):\n",
    "            hidden_states.append(torch.zeros(batch_size, self.hidden_size).to(device))\n",
    "            cell_states.append(torch.zeros(batch_size, self.hidden_size).to(device))\n",
    "        \n",
    "        # Output predictions (we predict all pixels except the first one)\n",
    "        # Changed shape to include num_classes dimension\n",
    "        outputs = torch.zeros(batch_size, height*width, self.num_classes).to(device)\n",
    "        \n",
    "        # Process pixels sequentially in raster scan order (outter for loop enforce autoregressive property)\n",
    "        # This is different from RNN where outter loop is for layers. \n",
    "        for i in range(height * width):\n",
    "            # Get current pixel (or zeros for the first pixel)\n",
    "            if i == 0:\n",
    "                pixel_input = torch.zeros(batch_size, self.input_channels).to(device)\n",
    "            else:\n",
    "                pixel_input = x_flat[:, 0, i-1].unsqueeze(1)\n",
    "            \n",
    "            # Forward through LSTM layers\n",
    "            layer_input = pixel_input\n",
    "            for l in range(self.num_layers):\n",
    "                hidden_states[l], cell_states[l] = self.cells[l](\n",
    "                    layer_input, \n",
    "                    (hidden_states[l], cell_states[l])\n",
    "                )\n",
    "                layer_input = hidden_states[l]\n",
    "            \n",
    "            # Predict next pixel (if not at the end)\n",
    "            if i < height * width:\n",
    "                prediction = self.output_layer(hidden_states[-1])\n",
    "                outputs[:, i] = prediction\n",
    "        \n",
    "        # Reshape outputs to maintain the class dimension\n",
    "        return outputs.view(batch_size, nc, height, width, self.num_classes)\n",
    "\n",
    "    def sample(self, batch_size=1, image_size=(28, 28), channels=1, device='cpu'):\n",
    "        height, width = image_size\n",
    "        generated_images = torch.zeros(batch_size, channels, height, width).to(device)\n",
    "        \n",
    "        # Initialize hidden and cell states for each layer\n",
    "        hidden_states = []\n",
    "        cell_states = []\n",
    "        for _ in range(self.num_layers):\n",
    "            hidden_states.append(torch.zeros(batch_size, self.hidden_size).to(device))\n",
    "            cell_states.append(torch.zeros(batch_size, self.hidden_size).to(device))\n",
    "        \n",
    "        # Generate pixels sequentially in raster scan order\n",
    "        for i in range(height * width):\n",
    "            # Get current pixel (or zeros for the first pixel)\n",
    "            if i == 0:\n",
    "                pixel_input = torch.zeros(batch_size, self.input_channels).to(device)\n",
    "            else:\n",
    "                # Use previously generated pixel as input\n",
    "                h_idx, w_idx = divmod(i-1, width)\n",
    "                pixel_input = generated_images[:, :, h_idx, w_idx].reshape(batch_size, channels)\n",
    "            \n",
    "            # Forward through LSTM layers\n",
    "            layer_input = pixel_input\n",
    "            for l in range(self.num_layers):\n",
    "                hidden_states[l], cell_states[l] = self.cells[l](\n",
    "                    layer_input, \n",
    "                    (hidden_states[l], cell_states[l])\n",
    "                )\n",
    "                layer_input = hidden_states[l]\n",
    "            \n",
    "            # Get prediction\n",
    "            logits = self.output_layer(hidden_states[-1])\n",
    "            \n",
    "            # Sample from the predicted distribution\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            pixel_values = torch.multinomial(probs, 1).float() / (self.num_classes - 1)\n",
    "            \n",
    "            # Place sampled pixel in the generated image\n",
    "            h_idx, w_idx = divmod(i, width)\n",
    "            generated_images[:, :, h_idx, w_idx] = pixel_values.view(batch_size, channels)\n",
    "        \n",
    "        return generated_images        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = PixelRNN(input_channels=1, hidden_size=32, num_layers=1, num_classes=256)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, _) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        batch_size, channels, height, width = inputs.size()\n",
    "        \n",
    "        # Quantize inputs to match output classes\n",
    "        targets = (inputs * (model.num_classes - 1)).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Rearrange outputs to (batch * height * width * channels, num_classes)\n",
    "        outputs_flat = rearrange(outputs, 'b c h w n -> (b h w c) n')\n",
    "        \n",
    "        # Rearrange targets to (batch * height * width * channels)\n",
    "        targets_flat = rearrange(targets, 'b c h w -> (b h w c)')\n",
    "    \n",
    "        loss = criterion(outputs_flat, targets_flat)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 10 == 9:\n",
    "            print(f'Epoch {epoch+1}, Batch {i+1}, Loss: {running_loss/100:.4f}')\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    samples = model.sample(batch_size=16, image_size=(28, 28), device=device)\n",
    "    # draw the sample using matplotlib\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(samples[i].view(samples.shape[-2], samples.shape[-1]).cpu().numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'pixelrnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
